\section{The Diversity of Workflow Models}\label{workflows}

One of the most challenging aspects of studying
workflows is the way the vocabulary has been overloaded unintentionally.
It is somewhat clearer to understand by starting from a historial
perspective.

The use and study of workflows and the initial implementation of workflow
management systems, viz., systems that manage one or more activities related
to workflows, and especially workflow execution, developed in the business
world with the need to automate business processes. Lud\"{a}scher et al.
ascribe the origins of workflows and workflow management systems to ``office
automation'' trends in the 1970s, \cite{ludascher_scientific_2006}. Van Der
Aalst argues that ``workflows'' arose from the needs of businesses to not only
execute tasks, but ``to manage the flow of work through the organization,''
and that managing workflows is the natural evolution from the monolithic
applications of the 1960s to applications that rely on external functionality
in the 1990s, \cite{van_der_aalst_application_1998}. By 1995, in the presence
of many workflow tools, the Workflow Management Coalition had developed a
``standard'' definition of workflows, \cite{hollingsworth_workflow_1993},

\begin{displayquote}
A Workflow is the automation of a business process, in whole or part, during
which documents, information or tasks are passed from one participant (a 
resource; human or machine) to another for action, according a set of 
procedural rules. 
\end{displayquote}

In the early 2000s, workflow systems started finding use in scientific
contexts where process automation was required for scientific uses
instead of traditional business uses. The focus of scientific workflows,
at the time, also shifted to focus primarily on data processing for
large ``grids'' of networked services, \cite{yu_taxonomy_2005}. Yu and Buyya
define a workflow as

\begin{displayquote}
... a collection of tasks that are processed on distributed resources in a
well-defined order to accomplish a specific goal.
\end{displayquote}

This latter definition is important because of what is missing: the human
element. For many in the grid/eScience workflows community this has become
the standard definition of a workflow and the involvement of humans
results not in a single workflow, but multiple workflows spanned by a human.
Machines or instruments are absent from the definition as well, but in
practice many modern grid workflows are launched automatically
when data ``comes off'' of instruments because they remain the primary
source of data in grid workflows, (c.f. - \cite{megino_panda:_2015}).

In addition to ``grid workflows,'' the scientific community started
exploring ``modeling and simulation workflows'' which focus not on data
flow, but on the orchestration of activities related to modeling and
simulation instead, sometimes on small local computers, but often on the
largest of the world's ``Leadership Class'' supercomputers. Unlike grid
workflows they tend to require human interaction in one way or another.
Some of these workflows are defined in the context of a particular way
of working, such as the Automation, Data, Environment, and Sharing
(ADES) model of Pizzi et al., \cite{pizzi_aiida:_2016}, the
``Design-to-Analysis'' model of Clay et al., \cite{clay_incorporating_2015}, or
the model of Billings et al.,\cite{billings_eclipse_2017}.

Additional types of workflows in the scientific community include
workflows that process ensembles of calculations for uncertainty quantification, verification and validation or probabilistic risk assessment, \cite{montoya_apex_2016},
and workflows that are used for testing software. These workflows share the property that they are all running a very large collection of jobs that only provide value when run together. However, they differ because testing workflows typically run each test as an independent task, whereas the other workflows may or may not change the tasks that are executed based on the intermediate state of the entire ensemble. These workflows require a large cluster or possibly a supercomputer in extreme cases.

Many scientific workflows have been hard-coded into dedicated environments - not general purpose workflow management systems - that serve as point solutions developed for the sole purpose of that single well-defined workflow, or at most a few, to meet the needs of a single community. This leads to an important defining characteristic for workflow management systems versus the point solutions: workflow management systems are extensible through a public Application Programming Interface or other method and extension does not, in general, require the intervention of the original author. "Embedding" workflows into point-solutions this may be the best solution in many cases, but the distinction between point-solutions and full workflow management systems is important because it clearly demonstrates  that some parties prefer to focus on rapidly creating new or modifying old workflows while others may only be interested in executing well-defined, very stable workflows.

Finally, an important class of scientific workflows is the set of ``conceptual workflows'' that broadly define activities based on the policies of a given community. These are common in large collaborations such as the Community Earth System Model (CESM), \cite{noauthor_cesm_nodate}. These workflows describe a series of activities that contain both human- and computer-controlled activities and look like business workflows. However, the level of detail tends to oscillate between very high and very low, as does the degree of abstraction, depending on the author. These workflows are important because they are often referred to in the same discussions as the other types of workflows described above. This illustrates the important fact that not all scientific workflows are machine executable, and it may be impossible to automate them in a workflow management system, even one that is very good at defining abstract workflows. It also demonstrates the difficulties that can arise in a discussion on workflows because of ambiguity in the definition.

\subsection{Taxonomies and
Classification}\label{taxonomies-and-classification}
There have been several efforts to classify, survey or develop taxonomies for workflows and workflow management systems and these efforts are significant in large part because they represent a collective call for higher order concepts in the space. Yu and Buyya present an exceptional and noteworthy taxonomy for grid workflows. Multiple other efforts provide highly useful vocabularies and analyses as
well.

Yu and Buyya developed a taxonomy for workflow management systems on
grids that sought to capture the architectural style while identifying
comparison criteria, \cite{yu_taxonomy_2005}. Their work is notable because it
largely avoids a discussion of applications and focuses purely on the
functional properties of the workflow management systems as they exist
on the grids. Their work also shows how thirteen common grid
workflow management systems, including Pegasus and Kepler, are covered by the
taxonomy. Like other authors, Yu and Buyya cite the lack of standardized
workflow syntax and language as sources of interoperability issues.

Scientific workflow management systems have flourished since their
inception, although not without significant overlap and duplication of
effort. The survey of scientific workflow management systems by Barker
and Hemert illustrates both growth and growing pains while also providing
important observations and recommendations on the topic,
\cite{barker_scientific_2007}.

Barker and Hemert also provide key insights into the history of
workflow management systems as an important part of business
automation. The authors make an important comparison between traditional
business workflow management systems and their scientific counterparts,
citing in particular that traditional business workflow tools employ the
wrong abstraction for scientists They define workflows using the
``standard'' definition from the Workflow Management Coalition, (c.f. \S \ref{workflows} above).

The discussion points that Barker and Hemert raise are important because
of their continuing importance and relevance today, particularly the
need to enable programmability through standard languages instead of
custom, proprietary languages. Sticking to
standards is also important and perhaps illustrated best by Barker's and
Hemert's statement that

\begin{displayquote}
If software development and tool support terminates on one proprietary 
framework, workflows will need to be re-implemented from scratch.
\end{displayquote}

This is an important point even for workflow tools that do not use
proprietary standards, but ``roll their own'' solutions. What can be
done to support those tools and reproduce those workflows once support
for continued development ends?

Montoya et al. discuss workflow needs for the Alliance for Application
Performance at Extreme Scale (APEX), \cite{nersc_apex_2016}, and describe
three main classes of workflows: Simulation Science, Uncertainty
Quantification (UQ), and High Throughput Computing (HTC),
\cite{montoya_apex_2016}.
HTC workflows start with the collection of data from experiments that is in turn
transported to large compute facilities for
processing. Many grid workflows are HTC workflows, but not all HTC
workflows are grid workflows since some HTC workflows - such as those
those presented by Montoya et al. - may be run on large resources that
are not traditionally ``grid machines.'' When Montoya et al. describe scientific workflows,
they are refering to the modeling and simulation workflows described above. Montoya et al. also provide a
detailed mapping of each workflow type to optimal hardware resources for the APEX
program.

The U.S. Department of Energy sponsored the \emph{DOE NGNS/CS Scientific
Workflows Workshop} on April 20-21st 2015. In the report, Deelman et al.
describe the requirements and research directions for scientific
workflows for the exascale environment, \cite{deelman_future_2015}\cite{deelman_future_2017}. The report (and paper) describes scientific workflows primarily by three application types:
Simulations, Instruments, and Collaborations. The findings of the workshop are
comprehensive and encouraging, with recommendations for research
priorities in Application Requirements, Hardware Systems, System
Software, Workflow Management System Design and Execution, Programming and Usability,
Provenance Capture, Validation, and Workflow Science.

The definitions of a ``workflow'' and ``workflow management systems''
are thoroughly explored and put into context for the purposes of the
workshop. The authors of the report are very careful to define workflows
not just as a collection of managed processes, which is common, but in
such a way that it is clear that reproducibility, mobility, and some
degree of generality are required by both the description of the
workflow and the management system. (N.B. - The report appears to provide three separate definitions for ``workflow'' on pages 6, 9 and 10.)

Ferreira da Silva et al. attempt to characterize workflow management systems in 
\cite{ferreira_da_silva_characterization_nodate}. The authors reduce key properties of workflow
systems into four incongruent areas: (i) design, (ii) execution and monitoring, (iii)
reusability and (iv) collaboration. These properties are essential
considerations for most  software with limited specificity for workflow
management systems. Furthermore, there is general conflation between
classification and taxonomy and significant incoherence between entries in
equivalence classes. Most significantly, it fluctuates somewhat chaotically
between discussing workflows and workflow management systems without linking
workflow properties to successful design and properties of workflow systems.
